## Java并发

并行：多个任务同时运行

并发：线程利用调度算法轮流执行

![image-20230315134809941](C:\Users\hua'wei\AppData\Roaming\Typora\typora-user-images\image-20230315134809941.png)

Runable是FunctionInterface（因为只有一个抽象方法）可以使用lamada

#### QPS、TPS和并发量

1. **QPS（Queries Per Second）：** QPS 表示每秒钟处理的查询请求数量。在数据库、网络服务等应用中，QPS 表示系统每秒能够处理的查询请求数量。计算方式：QPS = 总请求数 / 时间。
2. **TPS（Transactions Per Second）：** TPS 表示每秒钟处理的事务数量。事务可以是一组操作的集合，包括读取、写入、更新等。在金融交易、电子商务等应用中，TPS 表示系统每秒能够处理的事务数量。计算方式：TPS = 总事务数 / 时间。
3. **并发量（Concurrency）：** 并发量指的是同时处理的请求数量，即同时存在于系统中的请求的数量。高并发意味着系统能够同时处理大量的请求。计算方式通常没有直接的简单公式，它取决于系统的架构、并发控制、线程数等因素。

#### 创建新线程

- 实现Runnable接口：实现run()方法，使用start()方法启动线程
- 实现Callable接口：用FutureTask封装，可以将线程运行结果传递给其他的线程
- 继承Thread类：直接重写run()方法

线程状态：新建、可运行：新建后start、阻塞：未获取临界资源时、等待：获取到临界资源但条件不满足时、有时限等待用sleep

#### 线程池原理

1. **创建线程池**：在应用程序启动时，线程池会创建一定数量的线程（线程池中的线程数量通常称为线程池大小）。
2. **任务队列**：线程池会维护一个任务队列，用于存放需要执行的任务。当应用程序提交一个任务到线程池时，任务会被添加到任务队列中。
3. **任务调度**：线程池的调度器会从任务队列中取出任务，将任务分配给空闲的线程来执行。如果没有空闲线程，任务会等待直到有空闲线程可用。
4. **执行任务**：线程池中的线程会执行被分配的任务。当任务执行完毕后，线程会返回线程池，并等待下一个任务的分配。
5. **线程复用**：线程池会重复使用线程，避免了线程的频繁创建和销毁开销，提高了效率。
6. **线程管理**：线程池会监控线程的状态，如果线程因为异常退出或长时间不活动，线程池会回收该线程并创建新的线程来替代。
7. **动态调整**：一些线程池实现支持动态调整线程池大小，根据任务负载的变化来增加或减少线程数量，以适应不同的场景

###### 执行流程

1. **任务提交：** 当一个任务需要在线程池中执行时，应用程序会将任务提交给线程池。这可以通过调用线程池提供的提交方法来实现。
2. **任务队列：** 线程池通常会维护一个任务队列，用于存放待执行的任务。新提交的任务会被放入任务队列中。
3. **空闲线程：** 线程池中的线程在初始化时会被创建，它们会一直处于等待任务的状态，称为空闲线程。空闲线程会从任务队列中获取任务并执行。
4. **任务执行：** 当有空闲线程时，它会从任务队列中获取一个待执行的任务。线程会执行任务的主要操作，这可能涉及到计算、I/O操作等。
5. **任务完成：** 一旦任务执行完毕，线程会将执行结果返回给线程池。
6. **线程复用：** 执行完任务后，线程不会被销毁，而是继续等待从任务队列中获取下一个任务。这就实现了线程的复用，避免了频繁创建和销毁线程的开销。
7. **线程数量控制：** 线程池通常会限制同时运行的线程数量，以避免过多的线程占用过多的系统资源。
8. **异常处理：** 在任务执行过程中，可能会出现异常。线程池应该能够捕获并处理这些异常，以保证线程的稳定运行。
9. **线程池管理：** 线程池通常提供监控、管理和调优功能，允许调整线程池的参数，监视线程池的状态，以及处理一些特殊情况，如任务拒绝等。

#### 线程池参数作用

1. **核心线程数（Core Pool Size）**：
	- **作用**：定义线程池的核心线程数量，即线程池维护的最小线程数。
	- **作用范围**：线程池中始终保持这些线程的活动状态，即使它们当前没有处理任务。
	- **目的**：确保线程池始终能够及时响应任务的执行。
2. **最大线程数（Maximum Pool Size）**：
	- **作用**：定义线程池的最大线程数量，即线程池能够容纳的最大线程数。
	- **作用范围**：当任务数量超过核心线程数且工作队列已满时，线程池会创建新的线程，但不会超过最大线程数。
	- **目的**：限制线程池的最大负载，避免无限制地创建大量线程。
3. **工作队列（Work Queue）**：
	- **作用**：用于存放等待执行的任务。
	- **类型**：可以是有界队列（如ArrayBlockingQueue、LinkedBlockingQueue）或无界队列（如SynchronousQueue）。
	- **目的**：在核心线程数已满但未达到最大线程数时，任务会被存放在工作队列中，等待线程池有空闲线程时执行。
4. **线程存活时间（Keep Alive Time）**：
	- **作用**：定义非核心线程的空闲时间。
	- **目的**：当线程池中的线程数量超过核心线程数，空闲时间超过设定值时，多余的线程会被回收，直至线程数回到核心线程数为止。
5. **线程工厂（Thread Factory）**：
	- **作用**：用于创建线程。
	- **目的**：自定义线程的创建方式，可以设置线程名称、优先级等信息。
6. **拒绝策略（Rejected Execution Handler）**：
	- **作用**：定义当任务被拒绝执行时的处理策略。
	- **目的**：当工作队列已满且线程数达到最大线程数时，决定如何处理新提交的任务，常见的策略有抛出异常、直接丢弃、丢弃最老的任务、调用提交任务的线程来执行等。

#### Executor

- CachedThreadPool：可以自动调整的线程池
	- 会造成无限制的内存创建、内存占用、线程频繁的创建和销毁、无法控制并发数

- FixedThreadPool：所有任务只能使用固定大小的线程
- SingleThreadExecutor：大小为1的FixedThreadPool

#### synchronized

###### 同步代码块

```java
public void func() {
  synchronized(this) {
    // ...
  }
}
```

###### 同步一个方法

```java
public synchronized void func() {
	//...
}
```

###### 同步一个类

```java
public func() {
	synchronized(SynchornizedExample.class) {
    // ...
  }
}
```

###### 底层原理

1. **监视器锁：** 在 Java 对象头中，包含一个标记用于表示对象的锁状态，其中的一种状态就是监视器锁。一个对象可以有一个关联的监视器锁。
2. **进入 synchronized 代码块：** 当线程尝试进入一个被 `synchronized` 修饰的代码块时，它首先会尝试获取对象的监视器锁。如果这个锁没有被其他线程占用，当前线程就会获取到锁，然后执行临界区代码。
3. **竞争和阻塞：** 如果多个线程同时竞争获取同一个对象的监视器锁，只有一个线程会成功，其他线程会进入阻塞状态，等待锁的释放。
4. **锁的释放：** 当持有锁的线程退出 `synchronized` 代码块或方法时，它会释放锁，此时等待的其他线程中的一个会被唤醒，获取到锁，然后执行自己的临界区代码。
5. **可重入性：** Java 中的监视器锁是可重入的，意味着同一个线程可以多次获取同一个锁，不会阻塞自己。这种机制避免了死锁问题。
6. **锁的作用域：** `synchronized` 既可以修饰代码块，也可以修饰方法。在方法上使用 `synchronized` 相当于将整个方法体都作为临界区，而在代码块上使用 `synchronized` 则限定了更精确的临界区。

###### Java监视器锁底层

1. **对象头（Object Header）：** Java 对象的内存布局中，包含了一部分头信息，称为对象头。这个头信息中包含了各种标志位和指针，用于支持 Java 对象的管理和操作。其中的一部分用于支持监视器锁。
2. **锁标志位：** 在对象头中，有一些标志位用于表示对象的锁状态。其中包括是否被锁定、是否被偏向锁等。当一个对象被加锁时，这些标志位会被设置，以表示对象的锁定状态。
3. **同步块（Synchronized Block）：** 每个对象都可以关联一个同步块信息。同步块是用于实现对象级别的锁的关键部分。当一个线程进入 `synchronized` 代码块时，会尝试获取对象的监视器锁，同时会检查同步块信息，以确定是否有其他线程在同一对象上等待获取锁。
4. **等待集（Wait Set）和锁拥有者：** 当一个线程进入 `synchronized` 代码块时，如果发现对象已被其他线程锁定，它会将自己加入对象的等待集中，然后进入等待状态。同时，对象头中会记录当前锁的拥有者，以确保只有持有锁的线程才能执行临界区代码。
5. **锁升级：** Java 的锁可以根据并发情况进行升级或降级。例如，偏向锁可以升级为轻量级锁，然后再升级为重量级锁，以适应不同的并发场景。

#### ReetrantLock

ReentrantLock（可重入锁）是Java语言中的一种高级锁机制，用于实现线程同步和资源互斥。与传统的synchronized关键字相比，ReentrantLock提供了更多的灵活性和功能，能够解决一些synchronized所不能满足的需求。

1. **可重入性：** 与synchronized一样，ReentrantLock也支持可重入性。这意味着同一个线程可以多次获取同一个锁，而不会被阻塞。这对于需要在多个方法之间进行同步的情况非常有用。
2. **公平性和非公平性：** ReentrantLock可以选择是公平锁还是非公平锁。公平锁会按照线程请求锁的顺序来分配锁，而非公平锁则不考虑线程的请求顺序。默认情况下，ReentrantLock是非公平锁。
3. **等待可中断：** ReentrantLock提供了可以中断等待的能力。这意味着当一个线程在等待获取锁时，其他线程可以通过中断该线程来使其放弃获取锁。
4. **超时获取锁：** ReentrantLock允许线程在一定时间内尝试获取锁，如果超过指定的时间仍未获取到锁，线程可以根据需要执行其他操作。
5. **条件变量：** ReentrantLock支持条件变量（Condition），可以通过这些条件变量实现更复杂的线程通信和等待-通知机制。每个ReentrantLock对象都可以关联多个条件变量。
6. **可选择性的绑定多个条件：** 一个ReentrantLock可以与多个条件关联，通过使用不同的条件变量，可以在同一个锁上实现更细粒度的线程等待和唤醒。

###### 实现原理

1. **底层同步器 AQS：** `ReentrantLock` 的实现依赖于 `AbstractQueuedSynchronizer`（AQS），它是 Java 并发包中的一个框架，提供了实现锁和其他同步组件的基础。
2. **状态变量：** `ReentrantLock` 的底层同步器 AQS 通过一个整型变量来表示锁的状态。当锁处于未锁定状态时，状态值为 0；当某个线程获得锁时，状态值增加。因为 `ReentrantLock` 支持重入，所以状态值可以大于 1，代表某个线程多次获得锁。
3. **AQS 的队列：** 当多个线程竞争锁时，未能获得锁的线程会被放入 AQS 的队列中。队列采用先进先出（FIFO）的顺序，等待线程会被放到队列的尾部。
4. **独占模式：** `ReentrantLock` 是一个独占锁，一次只能有一个线程获得锁。当一个线程获得锁时，它会占据锁资源，其他线程将被阻塞，直到拥有锁的线程释放锁。
5. **可重入性：** `ReentrantLock` 支持重入，也就是说，当一个线程再次获得已经由它自己持有的锁时，它不会被阻塞。`ReentrantLock` 会记录获得锁的次数，每次释放锁时，计数减少，直到计数为 0 才真正释放锁。
6. **公平和非公平：** `ReentrantLock` 支持公平锁和非公平锁。在公平模式下，等待锁的线程将按照 FIFO 的顺序获得锁；在非公平模式下，等待锁的线程可能会抢占锁资源，不遵循严格的排队顺序。

###### 可重入实现原理

1. 当一个线程第一次获取 `ReentrantLock` 时，它会将 AQS 的状态值加 1，并将当前线程标识为持有锁的线程。此时，AQS 的状态值表示锁的持有次数。
2. 如果同一个线程再次获取 `ReentrantLock`，它会检查当前线程是否已经持有锁。如果是，则直接将 AQS 的状态值加 1，表示重入次数增加。
3. 当线程释放锁时，它会将 AQS 的状态值减 1。如果减到 0，表示锁完全释放；如果减到非零值，表示锁仍然被持有，只是重入次数减少。

#### Happens-Before 原则

1. **程序次序规则**：在同一个线程中，按照程序代码的先后顺序，前面的操作 Happens-Before 后面的操作。
2. **监视器锁规则**：对一个监视器锁的解锁 Happens-Before 后续对这个监视器锁的加锁。
3. **volatile 变量规则**：对一个 volatile 变量的写操作 Happens-Before 后续对这个 volatile 变量的读操作。
4. **传递性**：如果操作 A Happens-Before 操作 B，操作 B Happens-Before 操作 C，则操作 A Happens-Before 操作 C。
5. **线程启动规则**：一个线程的启动操作 Happens-Before 于该线程启动后的任意操作。
6. **线程终止规则**：一个线程的所有操作 Happens-Before 于其他线程检测到该线程已经终止。
7. **线程中断规则**：对线程 interrupt() 方法的调用 Happens-Before 等待这个线程的任何操作。

#### 同步锁的爆炸

锁爆炸通常发生在以下情况：

1. **热点数据**：多个线程同时访问一个热点数据，导致这些线程在竞争同一个锁。
2. **共享资源**：多个线程在访问共享资源时，需要获取同一个锁。
3. **同步代码块过长**：如果同步代码块执行时间过长，会增加其他线程等待获取锁的时间，导致锁爆炸。
4. **锁粒度不合适**：锁的粒度过细或过大都可能导致锁竞争问题，需要根据实际情况进行合理的设计。

锁爆炸可能导致的问题包括：

1. **性能下降**：大量线程在等待锁的释放，会导致系统性能急剧下降，响应时间延长。
2. **资源浪费**：大量线程在空转等待，会浪费系统资源，降低系统的吞吐量。
3. **死锁**：如果锁等待链中有环路，可能导致死锁的发生。

为了减少锁爆炸的影响，可以采取以下措施：

1. **锁粒度优化**：根据实际情况，选择合适的锁粒度，避免过细或过大的锁。
2. **减小锁持有时间**：优化同步代码块，尽量缩短锁的持有时间，减少其他线程的等待时间。
3. **并发数据结构**：使用并发数据结构，如ConcurrentHashMap，减少对全局锁的竞争。
4. **锁分段**：对于某些数据结构，可以将其分成多个段，每个段有独立的锁，减少锁竞争。
5. **乐观锁**：适当情况下，可以使用乐观锁来减少锁竞争，例如使用版本号来判断数据是否被修改。

#### 公平锁和非公平锁

公平锁和非公平锁的区别在于它们在等待队列中获取锁的方式。公平锁会按照线程请求锁的顺序来依次获 取锁，而非公平锁则不保证获取锁的顺序，有可能新请求锁的线程会插队获取锁，导致等待时间更长的线 程一直无法获得锁。 

公平锁可以避免线程饥饿现象的发生，即某些线程一直无法获得锁，而非公平锁则可能会导致线程饥饿现 象的发生。但是，公平锁的效率通常比非公平锁低，因为线程需要等待更长的时间才能获取锁。

#### 可重入锁、偏向锁、自旋锁、轻量级锁和重量级锁

可重入锁的特点是，当一个线程持有锁时，它可以再次获取该锁，而不会发生死锁或其他异常情况。这种 机制可以避免由于同一个线程多次调用同步方法而导致的死锁问题，同时也可以提高并发性能。

偏向锁是一种针对无竞争场景的优化机制，用于减少锁的竞争和提高并发性能。当一个线程获取锁时， JVM会将对象头部记录下该线程的ID，并将对象头部的标记位设置为“偏向锁”状态。此时，该线程可以直 接访问该对象，无需进行同步操作。如果其他线程也要访问该对象，那么偏向锁就会失效，对象头部的标 记位会升级为轻量级锁或重量级锁。 

自旋锁是一种用于多线程编程的同步机制。在多线程环境下，多个线程可能同时访问共享资源，如果不加 控制地访问，就可能出现数据竞争等问题。自旋锁的作用就是保证在同一时刻只有一个线程可以访问共享 资源，其他线程需要等待。与互斥锁不同的是，当一个线程尝试获取自旋锁时，如果发现自旋锁已经被其 他线程占用，它不会被阻塞，而是会一直循环忙等（自旋）直到自旋锁被释放。因此，自旋锁适用于保护 共享资源的访问时间非常短的情况。 

轻量级锁是一种优化锁的机制，用于减少锁的竞争和提高并发性能。当一个线程获取锁时，JVM会尝试将 对象头部记录下该线程的ID，然后使用CAS（Compare and Swap）指令来将对象头部的标记位设置为“轻 量级锁”状态。此时，其他线程仍然可以访问该对象，但是它们会自旋等待锁的释放。如果自旋等待的时间 超过一定阈值，或者发生竞争，那么轻量级锁就会升级为重量级锁。

重量级锁是一种传统的锁机制，它使用操作系统的互斥量来实现线程同步。当一个线程获取锁时，JVM会 将该线程阻塞，直到锁被释放为止。这种锁机制会导致线程上下文切换的开销，因此效率较低，但它可以 保证线程安全和数据一致性。

#### AQS

1. **状态（State）：** AQS 通过一个整数状态来表示同步器的状态。不同的同步器可以根据状态的含义来进行自定义，例如锁的状态可以表示是否被占用。
2. **等待队列（Wait Queue）：** AQS 内部维护了一个等待队列，用于存放等待资源的线程。等待队列使用双向链表来组织，线程会被加入队列尾部，当条件满足时被唤醒。
3. **共享模式和独占模式：** AQS 支持两种同步模式，即共享模式和独占模式。共享模式适用于多个线程可以同时访问的情况，如读写锁。独占模式适用于只允许一个线程访问的情况，如独占锁。
4. **同步器方法：** AQS 提供了一系列的同步方法，供子类实现。其中包括了获取锁、释放锁、判断锁是否可用等方法，子类可以根据自己的需求重写这些方法。

###### CountdownLatch

- 用来控制一个线程等待多个线程
- 维护了一个计数器cnt，每次调用countDown()方法会让计数器的值减1，减到0的时候，哪些因为调用await()方法方法而在等待的线程就会被唤醒

###### CyclicBarrier

- 用来控制多个线程互相等待，只有当多个线程到达时，这些线程才会继续执行
- 和CountdownLatch相似，都是通过维护计数器来实现，区别在于通过reset()方法可以循环使用

###### Semaphore

- 信号量，控制对互斥资源访问的线程数

###### AQS设计模式

1. **模板方法模式（Template Method Pattern）**： AQS使用了模板方法模式，其中定义了一个模板方法 `acquire` 和 `release`，子类可以通过实现特定的方法来实现不同类型的同步器，如独占锁、共享锁等。子类通过扩展AQS，提供具体的同步逻辑，而模板方法（`acquire` 和 `release`）提供了通用的调用框架。
2. **观察者模式（Observer Pattern）**： AQS中的等待队列机制涉及到观察者模式。在AQS中，等待队列中的线程（观察者）等待状态的改变，一旦状态满足条件，就会通知等待的线程继续执行。这种机制在ReentrantLock等锁中体现，等待队列中的线程等待锁的释放，一旦锁释放，等待的线程被唤醒。
3. **策略模式（Strategy Pattern）**： AQS中的同步策略可以被视为策略模式的一种应用。不同类型的同步器，如独占锁、共享锁，采用不同的同步策略来满足不同的需求。通过子类继承和扩展，可以定制特定的同步策略。
4. **工厂方法模式（Factory Method Pattern）**： AQS的子类，如ReentrantLock和Semaphore，都可以看作是工厂方法的应用。它们提供了不同类型的同步器实例，以满足不同场景的需求。
5. **单例模式（Singleton Pattern）**： AQS中的同步状态（state）是一个共享的资源，因此在设计中需要保证只有一个实例维护这个状态。AQS的状态是由一个整数来表示的，确保了全局唯一的状态管理。

#### BlockingQueue

用于实现一个支持阻塞操作的队列。它提供了一组方法，允许线程在队列为空或已满的情况下进行阻塞等待，从而实现线程之间的协调和同步。`BlockingQueue` 主要用于在多线程环境下进行生产者-消费者模型的实现。

- `put(E element)`：将元素添加到队列中，如果队列已满，则阻塞等待直到有空间。
- `take()`：从队列中获取并删除一个元素，如果队列为空，则阻塞等待直到有元素可取。
- `offer(E element)`：将元素添加到队列中，如果队列已满，则立即返回 false。
- `poll()`：从队列中获取并删除一个元素，如果队列为空，则立即返回 null。
- `offer(E element, long timeout, TimeUnit unit)`：将元素添加到队列中，在指定的时间范围内等待，如果队列仍然满，则返回 false。
- `poll(long timeout, TimeUnit unit)`：从队列中获取并删除一个元素，在指定的时间范围内等待，如果队列仍然为空，则返回 null。

#### 线程池

线程池是一种用于管理和复用线程的机制，它可以在程序启动时创建一定数量的线程，并将这些线程保存在一个池中，当需要执行任务时，从池中取出一个线程来执行任务，任务执行完成后，线程并不会被销毁，而是返回到池中等待下一次执行任务。

使用线程池的主要目的是提高程序的性能和稳定性，具体来说，它有以下几个好处：

1. 降低线程创建和销毁的开销：线程的创建和销毁是比较耗费系统资源的操作，如果每次执行任务都要创建一个新线程，会导致系统开销较大。使用线程池可以避免这个问题，因为线程池中的线程可以被复用，从而降低了线程创建和销毁的开销。
2. 提高程序的响应速度：线程池中的线程可以立即执行任务，而不需要等待线程的创建和启动，从而提高了程序的响应速度。
3. 提高系统的稳定性：线程池可以限制系统中的并发线程数量，避免因线程过多导致系统资源耗尽的情况发生。同时，线程池可以对线程进行统一的管理和监控，例如线程的状态、执行时间等信息，从而提高了系统的稳定性和可维护性。

#### 线程池的核心参数：

corePoolSize：核心线程数目   maximumPoolSize：最大线程数目  keepAliveTime：等待时间  unit：时间单位    workQueue：阻塞队列    threadFactory：线程工厂  handler：拒绝策略（使用线程还是剔除线程）

wait和sleep：LOCK.wait() Thread.sleep()

KeepAliveTime：控制线程在空闲状态下的存活时间

![image-20230315134743770](C:\Users\hua'wei\AppData\Roaming\Typora\typora-user-images\image-20230315134743770.png)

#### 线程池拒绝策略

**AbortPolicy（默认策略）：** 这是线程池默认的拒绝策略。当线程池无法处理新任务时，会抛出 `RejectedExecutionException` 异常，通知提交者任务无法被接受。使用该策略时，需要适当地处理这些异常，以防止应用程序崩溃。

**CallerRunsPolicy：** 在这个策略中，当线程池无法接受新任务时，线程池会使用提交任务的线程来执行被拒绝的任务。这个策略通常用于确保任务不会丢失，但需要注意如果拒绝任务的频率过高，可能会影响提交任务的线程的性能。

**DiscardPolicy：** 这个策略会默默地丢弃被拒绝的任务，没有任何通知。这意味着提交的任务可能会被忽略，潜在的数据丢失。

**DiscardOldestPolicy：** 这个策略会丢弃队列中最早被放入队列的任务，然后尝试再次提交被拒绝的任务。这个策略可能会导致一些旧的任务被丢弃。

提交任务的线程指的是执行线程池的线程，而不是具体执行任务的线程

#### Lock和synchronized：都是悲观锁

![image-20230315134757878](C:\Users\hua'wei\AppData\Roaming\Typora\typora-user-images\image-20230315134757878.png)

![image-20230315134847318](C:\Users\hua'wei\AppData\Roaming\Typora\typora-user-images\image-20230315134847318.png)

#### volatile关键字

1. 可见性：当一个线程修改了volatile变量的值时，其他线程可以立即看到这个修改。这是因为volatile变量的值会被写入到主内存中，其他线程读取该变量时会从主内存中读取最新的值。而普通变量则可能会存在线程间不可见的情况，即一个线程修改了变量的值，但其他线程并不能立即看到这个修改。
2. 有序性：当一个线程对volatile变量进行修改时，JVM会保证指令重排不会对该变量的读写顺序产生影响。这是因为JVM会在生成指令序列时，将volatile变量的读写指令插入到其他指令之间，以保证读写顺序的正确性。而普通变量则可能会存在指令重排的情况，即JVM为了提高程序性能，可能会对指令的执行顺序进行优化，这可能会导致变量的读写顺序不同于程序中的顺序。

Volatile能否保证线程安全：不能，只能保证可见性和有序性（摆烂器，不优化）

#### 悲观锁和乐观锁

悲观锁：顾名思义，就是比较悲观的锁，总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。

乐观锁：总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。

![image-20230315134855626](C:\Users\hua'wei\AppData\Roaming\Typora\typora-user-images\image-20230315134855626.png)

保证原子性：悲观锁——上锁，乐观锁——新旧值比较

#### HashTable和concurrentHashMap

![image-20230315134902184](C:\Users\hua'wei\AppData\Roaming\Typora\typora-user-images\image-20230315134902184.png)

**ThreadLocal**可以实现【资源对象】的线程隔离，线程间隔离，线程内共享

#### 对ThreadLocal的理解

![image-20230315134910615](C:\Users\hua'wei\AppData\Roaming\Typora\typora-user-images\image-20230315134910615.png)

###### 应用场景：

1. 数据库连接管理：在Web应用中，每个请求都需要从数据库中获取数据，因此需要使用连接池来管理数据库连接。使用ThreadLocal可以为每个线程提供一个独立的数据库连接，从而避免了线程安全的问题。
2. Session管理：在Web应用中，每个用户都有一个独立的Session对象，用于保存用户的登录状态等信息。使用ThreadLocal可以为每个线程提供一个独立的Session对象，从而避免了线程安全的问题。
3. 日志管理：在多线程环境下，如果多个线程共享同一个日志对象，那么就需要考虑线程安全的问题。使用ThreadLocal可以为每个线程提供一个独立的日志对象，从而避免了线程安全的问题。
4. 数据缓存：在一些计算密集型的应用中，如果多个线程共享同一个数据缓存对象，那么就需要考虑线程安全的问题。使用ThreadLocal可以为每个线程提供一个独立的数据缓存对象，从而避免了线程安全的问题。

#### NIO和AIO 

AIO和NIO都是Java中的I/O模型，不同之处在于它们的工作方式和底层实现。 

NIO（Non-blocking I/O）是Java 1.4引入的一种I/O模型，它使用**单线程轮询的方式实现多路复用**，可以同 时处理多个客户端连接。在NIO中，当一个连接有数据可读时，会通知线程进行读取操作，如果没有数据 可读，则线程可以继续处理其他连接。NIO的主要特点是非阻塞式的I/O操作，可以提高系统的吞吐量和并 发性能。 

AIO（Asynchronous I/O）是Java 1.7引入的一种I/O模型，它使用操作系统提供的**异步I/O机制**，通过回调函数的方式实现数据的处理。在AIO中，当一个连接有数据可读时，操作系统会通知Java应用程序进行读取操作，Java应用程序只需要等待通知即可，不需要进行轮询操作。AIO的主要特点是异步I/O操作，可以 提高系统的响应速度和资源利用率。 

在底层实现上，NIO使用了Java的Selector类实现多路复用，而AIO使用了操作系统提供的异步I/O机制。 NIO的缺点是在高并发情况下，单线程处理多个连接的效率可能会降低，而AIO则可以更好地处理高并发情 况下的I/O操作。 

总之，NIO适用于连接数较少、但数据处理量较大的场景，而AIO适用于连接数较多、但数据处理量较小的 场景。